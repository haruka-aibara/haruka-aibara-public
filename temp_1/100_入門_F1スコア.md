# F1スコア（F1 Score）

## 概要
F1スコアは、機械学習モデルの性能を評価するための重要な指標の一つです。特に分類問題において、精度（Precision）と再現率（Recall）の調和平均として計算され、モデルのバランスの取れた性能を評価するのに適しています。

## 詳細

### F1スコアの計算方法
F1スコアは以下の式で計算されます：

\[
F1 = 2 \times \frac{Precision \times Recall}{Precision + Recall}
\]

ここで：
- **Precision（精度）**: モデルが正と予測した中で、実際に正だった割合
- **Recall（再現率）**: 実際に正であるものの中で、モデルが正と予測できた割合

### 使用する利点
- 不均衡データセットでの評価に適している
- 精度と再現率のバランスを考慮した評価が可能
- 単一の数値でモデルの性能を表現できる

### 使用シーン
- 二値分類問題の評価
- 不均衡データセットでのモデル評価
- 医療診断や異常検知など、誤検知のコストが高い場合
- マルチクラス分類問題（マクロ平均、マイクロ平均として）

## 具体例

### Pythonでの実装例
```python
from sklearn.metrics import f1_score

# 二値分類の場合
y_true = [0, 1, 1, 0, 1, 1]
y_pred = [0, 1, 0, 0, 1, 1]

# 二値分類のF1スコア
f1 = f1_score(y_true, y_pred)
print(f"F1 Score: {f1}")

# マルチクラス分類の場合
y_true_multi = [0, 1, 2, 0, 1, 2]
y_pred_multi = [0, 2, 1, 0, 0, 1]

# マクロ平均F1スコア（クラスごとのF1スコアの平均）
f1_macro = f1_score(y_true_multi, y_pred_multi, average='macro')

# マイクロ平均F1スコア（全クラスを統合して計算）
f1_micro = f1_score(y_true_multi, y_pred_multi, average='micro')
```

### 実践的な使用例
- スパムメール検出：誤検知を最小限に抑えつつ、スパムを確実に検出
- 医療診断：病気の見落としを最小限に抑えつつ、誤診を防ぐ
- 異常検知：システムの異常を確実に検出しつつ、誤警報を最小限に

## まとめ
F1スコアは、機械学習モデルの性能評価において重要な指標です。特に以下の点で価値があります：

- 精度と再現率のバランスを考慮した評価
- 不均衡データセットでの適切な評価
- 単一の数値による直感的な性能評価
- 様々な分類問題への適用可能性

この指標を適切に理解し、使用することで、より正確なモデル評価と改善が可能になります。ただし、F1スコアはあくまで一つの指標であり、問題の性質に応じて他の評価指標と組み合わせて使用することが推奨されます。 
